{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dL40voW92Y4M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from transformers import  AdamW\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import re\n",
        "import math\n",
        "import gc\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from transformers import BertTokenizer\n",
        "import ast\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class PositionalEncoding(nn.Module):\n",
        "\n",
        "#     def __init__(self, d_model, dropout=0.1, max_len=24000):\n",
        "#         super(PositionalEncoding, self).__init__()\n",
        "#         self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "#         pe = torch.zeros(max_len, d_model)\n",
        "#         position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
        "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
        "#         pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "#         self.register_buffer('pe', pe)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x + self.pe[:x.size(0), :]\n",
        "#         return self.dropout(x)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=23187):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "        pe = torch.zeros((max_len, d_model)) \n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "class TransformerTextClassifier(nn.Module):\n",
        "    def __init__(self,ntoken, ninp, nhead, nhid, nlayers, num_classes, dropout=0.5, norm_first=True):\n",
        "        super(TransformerTextClassifier, self).__init__()\n",
        "        self.pos_encoder = PositionalEncoding(ninp)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(ninp, nhead, nhid, dropout, norm_first=norm_first)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.fc = nn.Linear(ninp, num_classes-1)\n",
        "        self.activation =nn.GELU() \n",
        "        #self.activation =nn.LeakyReLU()\n",
        "        \n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = output.mean(dim=1)  # Pooling layer (e.g., mean pooling)\n",
        "        output = self.fc(output)\n",
        "        # output = torch.sigmoid(output)  \n",
        "        return output\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "    # def init_weights(self):\n",
        "    #     initrange = 0.1\n",
        "    #     self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "    #     self.fc.bias.data.zero_()\n",
        "\n",
        "\n",
        "\n",
        "class IDDataset(Dataset):\n",
        "    def __init__(self, input_ids, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        id = self.input_ids[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return {\n",
        "            'input_ids': id,\n",
        "            'labels': label\n",
        "        }\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, token_ids, labels):\n",
        "        self.token_ids = token_ids\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        token_id = self.token_ids[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        return {\n",
        "            'input_ids': torch.tensor(token_id, dtype=torch.long),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n2M31yb62Msu"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(txt:str):\n",
        "\n",
        "    txt = re.sub('[^a-zA-Z]', ' ', txt)\n",
        "    txt = txt.lower()\n",
        "    txt = \" \".join(txt.split())\n",
        "\n",
        "    doc = nlp(txt)\n",
        "\n",
        "    tokens_filtered = []\n",
        "\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "\n",
        "        tokens_filtered.append(token.lemma_)\n",
        "\n",
        "    return \" \".join(tokens_filtered)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "def tokenize_and_convert(text):\n",
        "    # Tokenize the text using spaCy\n",
        "    spaCy_tokens = [token.text for token in nlp(text)]\n",
        "    \n",
        "    # Convert spaCy tokens to strings\n",
        "    token_strings = [str(token) for token in spaCy_tokens]\n",
        "    \n",
        "    # Map token strings to numerical IDs using the pre-trained tokenizer\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(token_strings)\n",
        "    \n",
        "    return token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "678aczQf2PIB",
        "outputId": "9ed79bc5-8652-42ec-8789-6c9dd9bff2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text         label\n",
            "0  I recently went through a breakup and she said...    depression\n",
            "1  I do not know how to navigate these feelings, ...    depression\n",
            "2  So I have been with my bf for 5 months , and h...    depression\n",
            "3  I am so exhausted of this. Just when I think I...  SuicideWatch\n",
            "4  I have been severly bullied since i was 5 till...    depression\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       count    %\n",
              "text       0  0.0\n",
              "label      0  0.0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the CSV file\n",
        "data = pd.read_csv('mental-health.csv')\n",
        "# Display the first few rows of the DataFrame\n",
        "print(data.head())\n",
        "data = data.drop_duplicates(ignore_index = True)\n",
        "df_null_values = data.isnull().sum().to_frame().rename(columns = {0:'count'})\n",
        "df_null_values['%'] = (df_null_values['count'] / len(data)) * 100\n",
        "df_null_values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3QsbkKPE2hSx"
      },
      "outputs": [],
      "source": [
        "data['text_prep'] = data['text'].apply(preprocess_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['token_id'] =  data['text_prep'].apply(tokenize_and_convert)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xwa4RZI52qw-"
      },
      "outputs": [],
      "source": [
        "LABELS = data['label'].unique()\n",
        "label2id = dict(zip(LABELS, np.arange(len(LABELS), dtype = np.float32)))\n",
        "data['label_prep'] = data['label'].map(label2id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.dropna(subset=['text_prep'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.to_csv('preprocessed_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "##########\n",
        "## load data if the preprocessed instead of reprocessed\n",
        "data = pd.read_csv('preprocessed_data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data[data['token_id'].isna()]['token_id'].head()\n",
        "# data['token_id'] = data['token_id'].fillna('[]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_string_to_array(s):\n",
        "    return np.array(ast.literal_eval(s))\n",
        "\n",
        "data['token_id']  = data['token_id'] .apply(convert_string_to_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_prep</th>\n",
              "      <th>token_id</th>\n",
              "      <th>label_prep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I recently went through a breakup and she said...</td>\n",
              "      <td>depression</td>\n",
              "      <td>recently go breakup say want friend say try ta...</td>\n",
              "      <td>[3728, 2175, 19010, 2360, 2215, 2767, 2360, 30...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I do not know how to navigate these feelings, ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>know navigate feeling new feeling stretch unde...</td>\n",
              "      <td>[2113, 22149, 3110, 2047, 3110, 7683, 3305, 27...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>So I have been with my bf for 5 months , and h...</td>\n",
              "      <td>depression</td>\n",
              "      <td>bf month tell depressed week particular happen...</td>\n",
              "      <td>[28939, 3204, 2425, 14777, 2733, 3327, 4148, 2...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I am so exhausted of this. Just when I think I...</td>\n",
              "      <td>SuicideWatch</td>\n",
              "      <td>exhausted think finally rest think maybe thing...</td>\n",
              "      <td>[9069, 2228, 2633, 2717, 2228, 2672, 2518, 270...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I have been severly bullied since i was 5 till...</td>\n",
              "      <td>depression</td>\n",
              "      <td>severly bully till result depressed misanthrop...</td>\n",
              "      <td>[100, 20716, 6229, 2765, 14777, 100, 100, 3674...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text         label  \\\n",
              "0  I recently went through a breakup and she said...    depression   \n",
              "1  I do not know how to navigate these feelings, ...    depression   \n",
              "2  So I have been with my bf for 5 months , and h...    depression   \n",
              "3  I am so exhausted of this. Just when I think I...  SuicideWatch   \n",
              "4  I have been severly bullied since i was 5 till...    depression   \n",
              "\n",
              "                                           text_prep  \\\n",
              "0  recently go breakup say want friend say try ta...   \n",
              "1  know navigate feeling new feeling stretch unde...   \n",
              "2  bf month tell depressed week particular happen...   \n",
              "3  exhausted think finally rest think maybe thing...   \n",
              "4  severly bully till result depressed misanthrop...   \n",
              "\n",
              "                                            token_id  label_prep  \n",
              "0  [3728, 2175, 19010, 2360, 2215, 2767, 2360, 30...         0.0  \n",
              "1  [2113, 22149, 3110, 2047, 3110, 7683, 3305, 27...         0.0  \n",
              "2  [28939, 3204, 2425, 14777, 2733, 3327, 4148, 2...         0.0  \n",
              "3  [9069, 2228, 2633, 2717, 2228, 2672, 2518, 270...         1.0  \n",
              "4  [100, 20716, 6229, 2765, 14777, 100, 100, 3674...         0.0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HeMACk9t5T3_"
      },
      "outputs": [],
      "source": [
        "X = data['token_id']\n",
        "y = data['label_prep']\n",
        "\n",
        "\n",
        "SEED = 1235\n",
        "train_ids_0, test_ids, train_labels_0, test_labels = tts(X, y, test_size = 0.1, random_state = SEED)\n",
        "train_ids, val_ids, train_labels, val_labels = tts(train_ids_0, train_labels_0, test_size = 0.2, random_state = SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "num_attention_heads = int(np.random.uniform(2, 4))\n",
        "num_attention_heads = 8\n",
        "embedding_size = int(np.random.uniform(120, 170)) # ninp should be bigger\n",
        "embedding_size = embedding_size - embedding_size % num_attention_heads\n",
        "nhidden = int(np.random.uniform(50, 300))\n",
        "nhidden = 70\n",
        "nlayers = int(np.random.uniform(2, 12))\n",
        "nlayers = 4\n",
        "Dropout = np.random.uniform(0.1, 0.12)\n",
        "#criterion = nn.CrossEntropyLoss() #FIXME\n",
        "criterion = nn.BCEWithLogitsLoss() \n",
        "learning_rate = np.random.uniform(1e-3, 0.01)\n",
        "learning_rate = 3e-3\n",
        "num_epochs = 4\n",
        "batch_size = 32\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# torch.cuda.set_device(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ZXxVUBzoxzZ5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2654787/3857427028.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_dataset = TensorDataset(torch.tensor(padded_train, dtype=torch.float), torch.tensor(train_labels, dtype=torch.float))\n",
            "/tmp/ipykernel_2654787/3857427028.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_dataset = TensorDataset(torch.tensor(padded_val, dtype=torch.float), torch.tensor(val_labels_array, dtype=torch.float))\n",
            "/tmp/ipykernel_2654787/3857427028.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_dataset =TensorDataset(torch.tensor(padded_test, dtype=torch.float), torch.tensor(test_labels_array, dtype=torch.float))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#old\n",
        "# vectorizer = TfidfVectorizer()\n",
        "# train_vectorizer = vectorizer.fit_transform(train_texts)\n",
        "# val_vectorizer   = vectorizer.transform(val_texts)\n",
        "# test_vectorizer  = vectorizer.transform(test_texts)\n",
        "\n",
        "# train_vectorizer = train_vectorizer.toarray()\n",
        "# val_vectorizer   = val_vectorizer.toarray()\n",
        "# test_vectorizer  = test_vectorizer.toarray()\n",
        "\n",
        "# _, ntoken = train_vectorizer.shape\n",
        "\n",
        "\n",
        "# train_dataset = TextDataset(train, train_labels)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "# val_dataset = TensorDataset(torch.tensor(val_vectorizer, dtype=torch.float), torch.tensor(val_labels_array, dtype=torch.float))\n",
        "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "# test_dataset = TensorDataset(torch.tensor(test_vectorizer, dtype=torch.float), torch.tensor(test_labels_array, dtype=torch.float))\n",
        "\n",
        "\n",
        "#new\n",
        "ntoken = len(nlp.vocab)\n",
        "ntoken= 37585\n",
        "val_labels_array = val_labels.values.astype(float)\n",
        "test_labels_array = test_labels.values.astype(float)\n",
        "\n",
        "# train_dataset = TextDataset(train_ids, train_labels)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# val_dataset = TextDataset(val_ids, val_labels)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# test_dataset = TextDataset(test_ids, test_labels) \n",
        "padded_train = pad_sequence([torch.tensor(seq) for seq in train_ids], batch_first=True, padding_value=0)\n",
        "padded_val = pad_sequence([torch.tensor(seq) for seq in val_ids], batch_first=True, padding_value=0)\n",
        "padded_test = pad_sequence([torch.tensor(seq) for seq in test_ids], batch_first=True, padding_value=0)\n",
        "\n",
        "train_dataset = TensorDataset(torch.tensor(padded_train, dtype=torch.float), torch.tensor(train_labels, dtype=torch.float))\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = TensorDataset(torch.tensor(padded_val, dtype=torch.float), torch.tensor(val_labels_array, dtype=torch.float))\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_dataset =TensorDataset(torch.tensor(padded_test, dtype=torch.float), torch.tensor(test_labels_array, dtype=torch.float))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters:\n",
            "num_attention_heads= 8\n",
            "embedding_size= 160\n",
            "nhidden= 70\n",
            "nlayers= 4\n",
            "dropout= 0.11010602677056984\n",
            "criterion= BCEWithLogitsLoss()\n",
            "learning_rate= 0.003\n",
            "num_epochs= 4\n",
            "batch_size= 32\n",
            "ntoken= 37585\n"
          ]
        }
      ],
      "source": [
        "# Print the hyperparameters\n",
        "print(\"Hyperparameters:\")\n",
        "print(f\"num_attention_heads= {num_attention_heads}\")\n",
        "print(f\"embedding_size= {embedding_size}\")\n",
        "print(f\"nhidden= {nhidden}\")\n",
        "print(f\"nlayers= {nlayers}\")\n",
        "print(f\"dropout= {Dropout}\")\n",
        "print(\"criterion=\", criterion)\n",
        "print(f\"learning_rate= {learning_rate}\")\n",
        "print(f\"num_epochs= {num_epochs}\")\n",
        "print(f\"batch_size= {batch_size}\")\n",
        "print(f\"ntoken= {ntoken}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/danielochana/anaconda3/envs/conda_deep/lib/python3.8/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "# model = TransformerModel(ntoken, embedding_size, num_attention_heads, nhidden, nlayers, Dropout, norm_first=True).to(device)\n",
        "model = TransformerTextClassifier( ntoken, embedding_size, num_attention_heads, nhidden, nlayers,2, Dropout, norm_first=True).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ## in order to run on a trained checkpoint: \n",
        "# num_attention_heads= 8\n",
        "# embedding_size= 160\n",
        "# nhidden= 70\n",
        "# nlayers= 4\n",
        "# dropout= 0.24840944810773966\n",
        "# batch_size= 16\n",
        "# ntoken= 37585\n",
        "# learning_rate= 0.0002\n",
        "# model = TransformerTextClassifier( ntoken, embedding_size, num_attention_heads, nhidden, nlayers,2, Dropout, norm_first=True).to(device)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# checkpoint = torch.load(\"model_checkpoint3.pth\")\n",
        "# model.load_state_dict(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wRoKNCUUwuKZ",
        "outputId": "bee0f2e1-7114-4d94-bafb-f5e0cf40761c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Batch [2/458], Loss: 8.212056159973145, train_acc: 50.00%\n",
            "Epoch [1/3], Batch [52/458], Loss: 0.8670637607574463, train_acc: 48.31%\n",
            "Epoch [1/3], Batch [102/458], Loss: 0.6990375518798828, train_acc: 51.62%\n",
            "Epoch [1/3], Batch [152/458], Loss: 0.6668969988822937, train_acc: 52.50%\n",
            "Epoch [1/3], Batch [202/458], Loss: 0.7227464318275452, train_acc: 52.94%\n",
            "Epoch [1/3], Batch [252/458], Loss: 1.142146110534668, train_acc: 52.19%\n",
            "Epoch [1/3], Batch [302/458], Loss: 0.674197256565094, train_acc: 55.44%\n",
            "Epoch [1/3], Batch [352/458], Loss: 0.8416059613227844, train_acc: 59.13%\n",
            "Epoch [1/3], Batch [402/458], Loss: 0.5665631890296936, train_acc: 57.69%\n",
            "Epoch [1/3], Batch [452/458], Loss: 0.7693417072296143, train_acc: 60.00%\n",
            "total_correct 2469, total_samples : 3663, Val Acc: 67.40%\n",
            "Epoch [2/3], Batch [2/458], Loss: 0.5110169649124146, train_acc: 67.19%\n",
            "Epoch [2/3], Batch [52/458], Loss: 0.6297664642333984, train_acc: 64.94%\n",
            "Epoch [2/3], Batch [102/458], Loss: 0.5829904675483704, train_acc: 65.06%\n",
            "Epoch [2/3], Batch [152/458], Loss: 0.5018784999847412, train_acc: 63.00%\n",
            "Epoch [2/3], Batch [202/458], Loss: 0.7284079790115356, train_acc: 62.62%\n",
            "Epoch [2/3], Batch [252/458], Loss: 0.7752057313919067, train_acc: 66.12%\n",
            "Epoch [2/3], Batch [302/458], Loss: 0.6424520611763, train_acc: 69.25%\n",
            "Epoch [2/3], Batch [352/458], Loss: 0.8318345546722412, train_acc: 66.44%\n",
            "Epoch [2/3], Batch [402/458], Loss: 0.5993427634239197, train_acc: 66.69%\n",
            "Epoch [2/3], Batch [452/458], Loss: 0.513558030128479, train_acc: 65.69%\n",
            "total_correct 2552, total_samples : 3663, Val Acc: 69.67%\n",
            "Epoch [3/3], Batch [2/458], Loss: 0.4034489095211029, train_acc: 75.00%\n",
            "Epoch [3/3], Batch [52/458], Loss: 0.5349608659744263, train_acc: 68.44%\n",
            "Epoch [3/3], Batch [102/458], Loss: 0.42904624342918396, train_acc: 74.19%\n",
            "Epoch [3/3], Batch [152/458], Loss: 0.4697890877723694, train_acc: 69.81%\n",
            "Epoch [3/3], Batch [202/458], Loss: 0.6444748640060425, train_acc: 73.06%\n",
            "Epoch [3/3], Batch [252/458], Loss: 0.5223853588104248, train_acc: 73.56%\n",
            "Epoch [3/3], Batch [302/458], Loss: 0.6792141199111938, train_acc: 69.19%\n",
            "Epoch [3/3], Batch [352/458], Loss: 0.5967981815338135, train_acc: 71.69%\n",
            "Epoch [3/3], Batch [402/458], Loss: 0.45950257778167725, train_acc: 70.50%\n",
            "Epoch [3/3], Batch [452/458], Loss: 0.8265517950057983, train_acc: 71.56%\n",
            "total_correct 2560, total_samples : 3663, Val Acc: 69.89%\n"
          ]
        }
      ],
      "source": [
        "losses =[]\n",
        "train_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_correct=0.0\n",
        "    total_samples=0.0\n",
        "\n",
        "    for batch_idx, (texts, labels) in enumerate(train_loader):\n",
        "        model.train()\n",
        "        # Convert texts and labels to tensors if necessary\n",
        "        texts = texts.to(device).long()  \n",
        "        labels = labels.to(device)\n",
        "\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(texts, None)\n",
        "        loss = criterion(outputs.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        outputs = torch.sigmoid(outputs) \n",
        "        predictions = (outputs > 0.5).float()\n",
        "        total_correct += (predictions[:,0] == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "        \n",
        "        if batch_idx % 50 == 1:\n",
        "            accuracy = total_correct / total_samples\n",
        "            losses.append(loss.item())\n",
        "            train_accuracies.append(accuracy)\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item()}, train_acc: {100. * accuracy:.2f}%\")\n",
        "            total_correct = 0.0\n",
        "            total_samples = 0.0\n",
        "\n",
        " \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        for texts, labels in val_loader:\n",
        "            texts = texts.to(device).long()  \n",
        "            labels = labels.to(device)\n",
        "            outputs = model(texts, None)\n",
        "            outputs = torch.sigmoid(outputs) \n",
        "            predictions = (outputs > 0.5).float()\n",
        "            total_correct += (predictions[:,0] == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "            accuracy = total_correct / total_samples\n",
        "    print(f'total_correct {total_correct}, total_samples : {total_samples}, Val Acc: {100. * accuracy:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "def accurary_est(y_pred, y_label):\n",
        "  y_pred = [0 if torch.sigmoid(i) < 0.5 else 1 for i in torch.tensor(y_pred)]\n",
        "  return sum([1 for res in range(len(y_pred)) if y_pred[res] == y_label[res]]) / len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_accuracies' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m ax1\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Plot train accuracies\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m ax2\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_accuracies\u001b[49m)\n\u001b[1;32m     11\u001b[0m ax2\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration / 50\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m ax2\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_accuracies' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot losses\n",
        "ax1.plot(losses)\n",
        "ax1.set_xlabel('Iteration / 50')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training Loss')\n",
        "\n",
        "# Plot train accuracies\n",
        "ax2.plot(train_accuracies)\n",
        "ax2.set_xlabel('Iteration / 50')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_title('Training Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model_checkpoint8.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_correct 10961, total_samples : 14651, Val Acc: 74.81%\n"
          ]
        }
      ],
      "source": [
        "# Final training results\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    for texts, labels in train_loader:\n",
        "        texts = texts.to(device).long()  \n",
        "        labels = labels.to(device)\n",
        "        outputs = model(texts, None)\n",
        "        outputs = torch.sigmoid(outputs) \n",
        "        predictions = (outputs > 0.5).float()\n",
        "        total_correct += (predictions[:,0] == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "        accuracy = total_correct / total_samples\n",
        "        # print(predictions[:,0])\n",
        "        # print(f'total_correct [{predictions.shape}, total_samples : {labels.shape}')\n",
        "print(f'total_correct {total_correct}, total_samples : {total_samples}, Val Acc: {100. * accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_correct 2560, total_samples : 3663, Val Acc: 69.89%\n"
          ]
        }
      ],
      "source": [
        "# Validation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    for texts, labels in val_loader:\n",
        "        texts = texts.to(device).long()  \n",
        "        labels = labels.to(device)\n",
        "        outputs = model(texts, None)\n",
        "        outputs = torch.sigmoid(outputs) \n",
        "        predictions = (outputs > 0.5).float()\n",
        "        total_correct += (predictions[:,0] == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "        accuracy = total_correct / total_samples\n",
        "        # print(predictions[:,0])\n",
        "        # print(f'total_correct [{predictions.shape}, total_samples : {labels.shape}')\n",
        "print(f'total_correct {total_correct}, total_samples : {total_samples}, Val Acc: {100. * accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_correct 1450, total_samples : 2035, test Acc: 71.25%\n"
          ]
        }
      ],
      "source": [
        "# Test results\n",
        "model.eval()\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "with torch.no_grad():\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for texts, labels in test_loader:\n",
        "        texts = texts.to(device).long()  \n",
        "        labels = labels.to(device)\n",
        "        outputs = model(texts, None)\n",
        "        outputs = torch.sigmoid(outputs) \n",
        "        predictions = (outputs > 0.5).float()\n",
        "        total_correct += (predictions[:,0] == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "        accuracy = total_correct / total_samples\n",
        "print(f'total_correct {total_correct}, total_samples : {total_samples}, test Acc: {100. * accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[38;5;28;01mdel\u001b[39;00m obj  \u001b[38;5;66;03m# This removes the reference to the tensor\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()  \u001b[38;5;66;03m# This releases any remaining GPU memory not in use\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdeallocate_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[16], line 6\u001b[0m, in \u001b[0;36mdeallocate_tensors\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28;01mdel\u001b[39;00m obj  \u001b[38;5;66;03m# This removes the reference to the tensor\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/conda_deep/lib/python3.8/site-packages/torch/cuda/memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "def deallocate_tensors():\n",
        "    for obj in gc.get_objects():\n",
        "        if torch.is_tensor(obj) :\n",
        "            if obj.device.type == 'cuda':\n",
        "                del obj  # This removes the reference to the tensor\n",
        "    torch.cuda.empty_cache()  # This releases any remaining GPU memory not in use\n",
        "\n",
        "deallocate_tensors()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.14453125\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_reserved()\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Release cached memory\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# After releasing cached memory\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/conda_deep/lib/python3.8/site-packages/torch/cuda/memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.memory_reserved()/(1024 ** 3))\n",
        "\n",
        "# Release cached memory\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# After releasing cached memory\n",
        "print(torch.cuda.memory_reserved()/(1024 ** 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total GPU Memory: 10.91 GB\n",
            "Allocated Memory: 0.06 GB\n",
            "Cached Memory: 0.14 GB\n",
            "Free Memory: 10.71 GB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def check_gpu_capacity():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        properties = torch.cuda.get_device_properties(device)\n",
        "        total_memory = properties.total_memory / (1024 ** 3)  # Convert bytes to gigabytes\n",
        "        memory_allocated = torch.cuda.memory_allocated(device) / (1024 ** 3)  # Allocated memory in use\n",
        "        memory_cached = torch.cuda.memory_reserved(device) / (1024 ** 3)  # Cached but not currently in use\n",
        "        free_memory = total_memory - memory_allocated - memory_cached\n",
        "        print(f\"Total GPU Memory: {total_memory:.2f} GB\")\n",
        "        print(f\"Allocated Memory: {memory_allocated:.2f} GB\")\n",
        "        print(f\"Cached Memory: {memory_cached:.2f} GB\")\n",
        "        print(f\"Free Memory: {free_memory:.2f} GB\")\n",
        "    else:\n",
        "        print(\"CUDA is not available.\")\n",
        "# gc.collect()\n",
        "check_gpu_capacity()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch.nn as nn\n",
        "# class block(nn.Module):\n",
        "# \tdef __init__(self):\n",
        "# \t\tsuper(block, self).__init__()\n",
        "# \t\tself.attention = nn.MultiheadAttention(embeds_size, num_heads, batch_first=True)\n",
        "# \t\tself.ffn = nn.Sequential(\n",
        "# \t\t\tnn.Linear(embeds_size, 2 * embeds_size),\n",
        "# \t\t\tnn.LeakyReLU(),\n",
        "# \t\t\tnn.Linear(2 * embeds_size, embeds_size),\n",
        "# \t\t)\n",
        "# \t\tself.drop1 = nn.Dropout(drop_prob)\n",
        "# \t\tself.drop2 = nn.Dropout(drop_prob)\n",
        "# \t\tself.ln1 = nn.LayerNorm(embeds_size)\n",
        "# \t\tself.ln2 = nn.LayerNorm(embeds_size)\n",
        "\n",
        "# \tdef forward(self, hidden_state):\n",
        "# \t\tattn, _ = self.attention(hidden_state, hidden_state, hidden_state, need_weights=False)\n",
        "# \t\tattn = self.drop1(attn)\n",
        "# \t\tout = self.ln1(hidden_state + attn)\n",
        "# \t\tobserved = self.ffn(out)\n",
        "# \t\tobserved = self.drop2(observed)\n",
        "# \t\treturn self.ln2(out + observed)\n",
        "\t\n",
        "\n",
        "# class transformer(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(transformer, self).__init__()\n",
        "\n",
        "#         self.tok_emb = nn.Embedding(vocab_size, embeds_size)\n",
        "#         self.pos_emb = nn.Embedding(block_size, embeds_size)\n",
        "#         self.block = block()\n",
        "#         self.ln1 = nn.LayerNorm(embeds_size)\n",
        "#         self.ln2 = nn.LayerNorm(embeds_size)\n",
        "\n",
        "#         self.classifier_head = nn.Sequential(\n",
        "#             nn.Linear(embeds_size, embeds_size),\n",
        "#             nn.LeakyReLU(),\n",
        "#             nn.Dropout(drop_prob),\n",
        "#             nn.Linear(embeds_size, embeds_size),\n",
        "#             nn.LeakyReLU(),\n",
        "#             nn.Linear(embeds_size, num_classes),\n",
        "#             nn.Softmax(dim=1),\n",
        "#         )\n",
        "\n",
        "#         print(\"number of parameters: %.2fM\" % (self.num_params()/1e6,))\n",
        "\n",
        "#     def num_params(self):\n",
        "#         n_params = sum(p.numel() for p in self.parameters())\n",
        "#         return n_params\n",
        "\n",
        "#     def forward(self, seq):\n",
        "#         B,T = seq.shape\n",
        "#         embedded = self.tok_emb(seq)\n",
        "#         embedded = embedded + self.pos_emb(torch.arange(T, device=device))\n",
        "#         output = self.block(embedded)\n",
        "#         output = output.mean(dim=1)\n",
        "#         output = self.classifier_head(output)\n",
        "#         return output\n",
        "    \n",
        "\n",
        "# model = transformer()\n",
        "# model.to(device)\n",
        "# vocab_size = 20000\n",
        "\n",
        "# block_size = 200\n",
        "# embeds_size = 100\n",
        "# num_classes = 2\n",
        "# drop_prob = 0.13\n",
        "# batch_size = 32\n",
        "# epochs = 30\n",
        "# num_heads = 4\n",
        "# head_size = embeds_size // num_heads\n",
        "# model_path = 'model_classification.pth'\n",
        "# model_loader = False\n",
        "\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "# \tlosses = 0\n",
        "# \tfor (inputs, targets) in train_data:\n",
        "# \t\tinputs = inputs.to(device)\n",
        "# \t\ttargets = targets.to(device)\n",
        "# \t\toutput = model(inputs)\n",
        "# \t\tloss = model_loss(output, targets)\n",
        "# \t\tmodel_optimizer.zero_grad()\n",
        "# \t\tloss.backward()\n",
        "# \t\tmodel_optimizer.step()\n",
        "# \t\tlosses += loss.item()\n",
        "# \tprint(f'[{epoch}][Train]', losses)\n",
        "# \tmodel.eval()\n",
        "# \ttest_loss = 0\n",
        "# \tpassed = 0\n",
        "# \tfor (inputs, targets) in test_data:\n",
        "# \t\twith torch.no_grad():\n",
        "# \t\t\tinputs = inputs.to(device)\n",
        "# \t\t\ttargets = targets.to(device)\n",
        "# \t\t\toutputs = model(inputs)\n",
        "# \t\t\tif outputs.argmax() == targets.argmax():\n",
        "# \t\t\t\tpassed += 1\n",
        "# \tmodel.train()\n",
        "# \tprint(f'[{epoch}][Test]', ', accuracy', passed / len(dataset_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
